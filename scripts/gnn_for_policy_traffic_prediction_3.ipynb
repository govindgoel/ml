{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def create_dataloader(is_train, batch_size, dataset, train_ratio):\n",
    "    dataset_length = len(dataset)\n",
    "    print(f\"Total dataset length: {dataset_length}\")\n",
    "\n",
    "    # Calculate split index for training and validation\n",
    "    split_idx = int(dataset_length * train_ratio)\n",
    "    \n",
    "    # Calculate the maximum number of samples that fit into complete batches for training and validation\n",
    "    train_samples = (split_idx // batch_size) * batch_size\n",
    "    valid_samples = ((dataset_length - split_idx) // batch_size) * batch_size\n",
    "    if is_train:\n",
    "        indices = range(0, train_samples)\n",
    "    else:\n",
    "        indices = range(split_idx, split_idx + valid_samples)\n",
    "    sub_dataset = Subset(dataset, indices)\n",
    "    print(f\"{'Training' if is_train else 'Validation'} subset length: {len(sub_dataset)}\")\n",
    "    return DataLoader(dataset=sub_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "class MyGeometricDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "    \n",
    "def collate_fn(data_list):\n",
    "    return Batch.from_data_list(data_list)\n",
    "\n",
    "def normalize_data(dataset):\n",
    "    # Collect all node features\n",
    "    all_node_features = []\n",
    "    for data in dataset:\n",
    "        all_node_features.append(data.x)\n",
    "\n",
    "    # Stack all node features into a single tensor\n",
    "    all_node_features = torch.cat(all_node_features, dim=0)\n",
    "    \n",
    "    # Fit the min-max scaler on the node features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_node_features)\n",
    "\n",
    "    # Apply the scaler to each data instance and store as a new feature\n",
    "    for data in dataset:\n",
    "        data.normalized_x = torch.tensor(scaler.transform(data.x), dtype=torch.float)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def normalize_positional_features(dataset):\n",
    "    # Collect all positional features\n",
    "    all_pos_features = []\n",
    "    for data in dataset:\n",
    "        all_pos_features.append(data.pos)\n",
    "\n",
    "    # Stack all positional features into a single tensor\n",
    "    all_pos_features = torch.cat(all_pos_features, dim=0)\n",
    "    \n",
    "    # Fit the min-max scaler on the positional features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_pos_features)\n",
    "\n",
    "    # Apply the scaler to each data instance and store as a new feature\n",
    "    for data in dataset:\n",
    "        data.normalized_pos = torch.tensor(scaler.transform(data.pos), dtype=torch.float)\n",
    "    return dataset\n",
    "\n",
    "def normalize_y_values(dataset):\n",
    "    # Collect all y values\n",
    "    all_y_values = []\n",
    "    for data in dataset:\n",
    "        all_y_values.append(data.y)\n",
    "\n",
    "    # Stack all y values into a single tensor\n",
    "    all_y_values = torch.cat(all_y_values, dim=0)\n",
    "\n",
    "    # Fit the min-max scaler on the y values\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_y_values)\n",
    "\n",
    "    # Apply the scaler to each data instance and store as a new feature\n",
    "    for data in dataset:\n",
    "        data.normalized_y = torch.tensor(scaler.transform(data.y), dtype=torch.float)  # Keep the 2D shape\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "    # Normalize node features\n",
    "    dataset = normalize_data(dataset)\n",
    "    # Normalize positional features (if any)\n",
    "    dataset = normalize_positional_features(dataset)\n",
    "    # Normalize y values\n",
    "    dataset = normalize_y_values(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is the current working version. The steps are the following:\n",
    "\n",
    "1. Load data\n",
    "2. Load model and loss function\n",
    "3. Split into train and test data\n",
    "4. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "num_epochs = 500\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "wandb_name = 'gnn_decrease_model_for_one_batch'\n",
    "train_ratio = 0.8\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(1, 16)\n",
    "        # self.conv2 = torch_geometric.nn.GATConv(16, 16)\n",
    "        self.conv3 = torch_geometric.nn.GCNConv(16, 1)\n",
    "        # self.conv3 = torch_geometric.nn.GCNConv(16, 1)\n",
    "        # self.gat1 = torch_geometric.nn.GATConv(16, 16)\n",
    "        # self.conv4 = torch_geometric.nn.GCNConv(16, 1)\n",
    "                \n",
    "        # self.convWithPos = torch_geometric.nn.conv.PointNetConv(1, 16, 3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv3(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.gat1(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv4(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_batches = 0\n",
    "    with torch.inference_mode():\n",
    "        for idx, data in enumerate(valid_dl):\n",
    "            input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "            predicted = model(data)\n",
    "            val_loss += loss_func(predicted, targets).item()\n",
    "            num_batches += 1\n",
    "    return val_loss / num_batches if num_batches > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of dictionaries\n",
    "data_dict_list = torch.load('../results/dataset_1pm_0-1382.pt')\n",
    "\n",
    "# Reconstruct the Data objects\n",
    "datalist = [Data(x=d['x'], edge_index=d['edge_index'], pos=d['pos'], y=d['y']) for d in data_dict_list]\n",
    "\n",
    "# Recreate the dataset\n",
    "dataset = MyGeometricDataset(datalist)\n",
    "\n",
    "# Apply normalization to your dataset\n",
    "dataset_normalized = normalize_dataset(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yrfyx495) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e12071626df4fa2880666b3b024d48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">good-night-22</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/check_errors/runs/yrfyx495' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/check_errors/runs/yrfyx495</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/check_errors' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/check_errors</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240705_105415-yrfyx495/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yrfyx495). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2863dc90d2480088f8cfe4de9e0b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01116761805555547, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240705_105443-ibxbl6p0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/check_errors/runs/ibxbl6p0' target=\"_blank\">summer-capybara-23</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/check_errors' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/check_errors' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/check_errors</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/check_errors/runs/ibxbl6p0' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/check_errors/runs/ibxbl6p0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.init(\n",
    "        project=\"check_errors\",\n",
    "        config={\n",
    "            \"epochs\": num_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": lr,\n",
    "            # \"dropout\": 0.15,\n",
    "            })\n",
    "config = wandb.config\n",
    "model = GnnModel().to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GnnModel(\n",
       "  (conv1): GCNConv(1, 16)\n",
       "  (conv3): GCNConv(16, 1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdfadsf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m asdfadsf\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdfadsf' is not defined"
     ]
    }
   ],
   "source": [
    "asdfadsf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 1382\n",
      "Training subset length: 1100\n",
      "Total dataset length: 1382\n",
      "Validation subset length: 260\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "train_dl = create_dataloader(dataset=dataset_normalized, is_train=True, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "valid_dl = create_dataloader(dataset=dataset_normalized, is_train=False, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "print(n_steps_per_epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# for epoch in range(config.epochs):\n",
    "#     model.train()\n",
    "#     # data = next(iter(train_dl))\n",
    "#     # for idx in range(len(train_dl)):\n",
    "        \n",
    "#     for idx, data in enumerate(train_dl):\n",
    "#         input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "#         predicted = model(data)\n",
    "#         train_loss = loss_fct(predicted, targets)\n",
    "#         optimizer.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         wandb.log({\"train_loss\": train_loss.item(), \"epoch\": epoch, \"step\": idx})\n",
    "#         print(f\"epoch: {epoch}, step: {idx}, loss: {train_loss.item()}\")\n",
    "        \n",
    "#     val_loss = validate_model(model, valid_dl, loss_fct, device)\n",
    "#     wandb.log({\"val_loss\": val_loss})\n",
    "#     print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "        \n",
    "# wandb.summary[\"val_loss\"] = val_loss\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EarlyStopping:\n",
    "#     def __init__(self, tolerance=5, min_delta=0):\n",
    "#         self.tolerance = tolerance\n",
    "#         self.min_delta = min_delta\n",
    "#         self.counter = 0\n",
    "#         self.early_stop = False\n",
    "\n",
    "#     def __call__(self, train_loss, validation_loss):\n",
    "#         if (validation_loss - train_loss) > self.min_delta:\n",
    "#             self.counter +=1\n",
    "#             if self.counter >= self.tolerance:  \n",
    "#                 self.early_stop = True\n",
    "# early_stopping = EarlyStopping(tolerance=5, min_delta=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, val_loss: 36074.207331730766\n",
      "epoch: 1, val_loss: 24183.85486778846\n",
      "epoch: 2, val_loss: 78698.20673076923\n",
      "epoch: 3, val_loss: 102636.74699519231\n",
      "epoch: 4, val_loss: 101859.34975961539\n",
      "epoch: 5, val_loss: 90070.79627403847\n",
      "epoch: 6, val_loss: 76151.65204326923\n",
      "epoch: 7, val_loss: 63441.45823317308\n",
      "epoch: 8, val_loss: 52378.12319711538\n",
      "epoch: 9, val_loss: 61294.62319711538\n",
      "epoch: 10, val_loss: 45354.18028846154\n",
      "epoch: 11, val_loss: 34868.485877403844\n",
      "epoch: 12, val_loss: 27600.67022235577\n",
      "epoch: 13, val_loss: 22172.89287860577\n",
      "epoch: 14, val_loss: 18098.572415865383\n",
      "epoch: 15, val_loss: 14953.845552884615\n",
      "epoch: 16, val_loss: 12339.248422475961\n",
      "epoch: 17, val_loss: 10288.269756610576\n",
      "epoch: 18, val_loss: 8633.09990985577\n",
      "epoch: 19, val_loss: 7207.927396334135\n",
      "epoch: 20, val_loss: 6059.212552584135\n",
      "epoch: 21, val_loss: 5042.471529447115\n",
      "epoch: 22, val_loss: 4238.04052734375\n",
      "epoch: 23, val_loss: 3513.580866887019\n",
      "epoch: 24, val_loss: 2917.111328125\n",
      "epoch: 25, val_loss: 2395.1782977764424\n",
      "epoch: 26, val_loss: 1996.188467172476\n",
      "epoch: 27, val_loss: 1645.7814565805288\n",
      "epoch: 28, val_loss: 1367.5493727463943\n",
      "epoch: 29, val_loss: 1114.3700796274038\n",
      "epoch: 30, val_loss: 909.6910729041466\n",
      "epoch: 31, val_loss: 744.250967172476\n",
      "epoch: 32, val_loss: 605.9917461688702\n",
      "epoch: 33, val_loss: 492.4725388746995\n",
      "epoch: 34, val_loss: 399.4517798790565\n",
      "epoch: 35, val_loss: 322.77161818284253\n",
      "epoch: 36, val_loss: 257.79306851900543\n",
      "epoch: 37, val_loss: 201.17213205190805\n",
      "epoch: 38, val_loss: 151.0250478891226\n",
      "epoch: 39, val_loss: 62.706585517296425\n",
      "epoch: 40, val_loss: 11.995806987469013\n",
      "epoch: 41, val_loss: 2.7076124411362867\n",
      "epoch: 42, val_loss: 0.2723096517416147\n",
      "epoch: 43, val_loss: 0.05389326696212475\n",
      "epoch: 44, val_loss: 0.05754974341163269\n",
      "epoch: 45, val_loss: 0.05400111812811632\n",
      "epoch: 46, val_loss: 0.05149300654347126\n",
      "epoch: 47, val_loss: 0.04093703484305969\n",
      "epoch: 48, val_loss: 0.0897179778951865\n",
      "epoch: 49, val_loss: 0.14470658279382265\n",
      "epoch: 50, val_loss: 0.12164562367475949\n",
      "epoch: 51, val_loss: 0.10831875812548858\n",
      "epoch: 52, val_loss: 0.10214515145008381\n",
      "epoch: 53, val_loss: 0.09119648257127175\n",
      "epoch: 54, val_loss: 0.08125185393370114\n",
      "epoch: 55, val_loss: 0.07274800768265358\n",
      "epoch: 56, val_loss: 0.06538441204107724\n",
      "epoch: 57, val_loss: 0.057595846171562486\n",
      "epoch: 58, val_loss: 0.05185538816910524\n",
      "epoch: 59, val_loss: 0.0449722558259964\n",
      "epoch: 60, val_loss: 0.0406866712638965\n",
      "epoch: 61, val_loss: 0.036375803443101734\n",
      "epoch: 62, val_loss: 0.03290931593913298\n",
      "epoch: 63, val_loss: 0.029879839947590463\n",
      "epoch: 64, val_loss: 0.027485031777849563\n",
      "epoch: 65, val_loss: 0.02550844633235381\n",
      "epoch: 66, val_loss: 0.024370592230787642\n",
      "epoch: 67, val_loss: 0.023678268377597515\n",
      "epoch: 68, val_loss: 0.023108003947597284\n",
      "epoch: 69, val_loss: 0.022893223768243424\n",
      "epoch: 70, val_loss: 0.022851333738519594\n",
      "epoch: 71, val_loss: 0.022959051080621205\n",
      "epoch: 72, val_loss: 0.023200125075303592\n",
      "epoch: 73, val_loss: 0.023561480813301526\n",
      "epoch: 74, val_loss: 0.023939108189481955\n",
      "epoch: 75, val_loss: 0.024356197709074386\n",
      "epoch: 76, val_loss: 0.024773007688614037\n",
      "epoch: 77, val_loss: 0.02514733947240389\n",
      "epoch: 78, val_loss: 0.02550469869031356\n",
      "epoch: 79, val_loss: 0.02578137069940567\n",
      "epoch: 80, val_loss: 0.02604360033113223\n",
      "epoch: 81, val_loss: 0.026298929292422075\n",
      "epoch: 82, val_loss: 0.02648829038326557\n",
      "epoch: 83, val_loss: 0.026658937621575136\n",
      "epoch: 84, val_loss: 0.02679152858371918\n",
      "epoch: 85, val_loss: 0.026907165749714926\n",
      "epoch: 86, val_loss: 0.026992271582667645\n",
      "epoch: 87, val_loss: 0.027007513751204196\n",
      "epoch: 88, val_loss: 0.027039175280011617\n",
      "epoch: 89, val_loss: 0.027067540070185296\n",
      "epoch: 90, val_loss: 0.02707447870992697\n",
      "epoch: 91, val_loss: 0.0270849707034918\n",
      "epoch: 92, val_loss: 0.02708453584748965\n",
      "epoch: 93, val_loss: 0.027068783314182207\n",
      "epoch: 94, val_loss: 0.027036570728971407\n",
      "epoch: 95, val_loss: 0.026992950015343152\n",
      "epoch: 96, val_loss: 0.026935986458108976\n",
      "epoch: 97, val_loss: 0.026905516592355874\n",
      "epoch: 98, val_loss: 0.026856692221302252\n",
      "epoch: 99, val_loss: 0.026803030704076473\n",
      "epoch: 100, val_loss: 0.026744732203391883\n",
      "epoch: 101, val_loss: 0.026670027810793657\n",
      "epoch: 102, val_loss: 0.02661051142674226\n",
      "epoch: 103, val_loss: 0.026535832967895728\n",
      "epoch: 104, val_loss: 0.026492003781291153\n",
      "epoch: 105, val_loss: 0.026424251783352632\n",
      "epoch: 106, val_loss: 0.02633155409533244\n",
      "epoch: 107, val_loss: 0.02626253951054353\n",
      "epoch: 108, val_loss: 0.026189693607963048\n",
      "epoch: 109, val_loss: 0.026115547865629196\n",
      "epoch: 110, val_loss: 0.026035406555120762\n",
      "epoch: 111, val_loss: 0.025956846200502835\n",
      "epoch: 112, val_loss: 0.025876989158300254\n",
      "epoch: 113, val_loss: 0.02579029105030573\n",
      "epoch: 114, val_loss: 0.025695320075521104\n",
      "epoch: 115, val_loss: 0.025602423800871923\n",
      "epoch: 116, val_loss: 0.025514578733306665\n",
      "epoch: 117, val_loss: 0.02542317959551628\n",
      "epoch: 118, val_loss: 0.025334414954368886\n",
      "epoch: 119, val_loss: 0.025233966656602345\n",
      "epoch: 120, val_loss: 0.025135702955035064\n",
      "epoch: 121, val_loss: 0.025015645302259006\n",
      "epoch: 122, val_loss: 0.024918954389599655\n",
      "epoch: 123, val_loss: 0.024818567129281852\n",
      "epoch: 124, val_loss: 0.02470968635036395\n",
      "epoch: 125, val_loss: 0.024615669909578104\n",
      "epoch: 126, val_loss: 0.02448670781002595\n",
      "epoch: 127, val_loss: 0.024356675835756156\n",
      "epoch: 128, val_loss: 0.02423779064646134\n",
      "epoch: 129, val_loss: 0.024123439135459755\n",
      "epoch: 130, val_loss: 0.024005792032067593\n",
      "epoch: 131, val_loss: 0.023849074370585956\n",
      "epoch: 132, val_loss: 0.023738584409539517\n",
      "epoch: 133, val_loss: 0.023587185602921706\n",
      "epoch: 134, val_loss: 0.023473196734602634\n",
      "epoch: 135, val_loss: 0.023334756780129213\n",
      "epoch: 136, val_loss: 0.023189129021305304\n",
      "epoch: 137, val_loss: 0.023051192410863362\n",
      "epoch: 138, val_loss: 0.02290289892027011\n",
      "epoch: 139, val_loss: 0.02275485244507973\n",
      "epoch: 140, val_loss: 0.022601122609697856\n",
      "epoch: 141, val_loss: 0.02244930900633335\n",
      "epoch: 142, val_loss: 0.02228535468188616\n",
      "epoch: 143, val_loss: 0.022116533408944424\n",
      "epoch: 144, val_loss: 0.021982684158361875\n",
      "epoch: 145, val_loss: 0.021804579748557165\n",
      "epoch: 146, val_loss: 0.021613665354939606\n",
      "epoch: 147, val_loss: 0.021460931175030194\n",
      "epoch: 148, val_loss: 0.021267179829569962\n",
      "epoch: 149, val_loss: 0.021120838820934296\n",
      "epoch: 150, val_loss: 0.02094075083732605\n",
      "epoch: 151, val_loss: 0.020744615879196387\n",
      "epoch: 152, val_loss: 0.02054806913320835\n",
      "epoch: 153, val_loss: 0.02035195824618523\n",
      "epoch: 154, val_loss: 0.020152868846288093\n",
      "epoch: 155, val_loss: 0.019977830063838225\n",
      "epoch: 156, val_loss: 0.019764860948691003\n",
      "epoch: 157, val_loss: 0.01957704800252731\n",
      "epoch: 158, val_loss: 0.01936234189913823\n",
      "epoch: 159, val_loss: 0.01916599689194789\n",
      "epoch: 160, val_loss: 0.018940809827584486\n",
      "epoch: 161, val_loss: 0.018724154107845746\n",
      "epoch: 162, val_loss: 0.01851567210486302\n",
      "epoch: 163, val_loss: 0.018294737889216497\n",
      "epoch: 164, val_loss: 0.018082271974820357\n",
      "epoch: 165, val_loss: 0.017864828786024682\n",
      "epoch: 166, val_loss: 0.017632373250447787\n",
      "epoch: 167, val_loss: 0.017430996379027\n",
      "epoch: 168, val_loss: 0.017188060025756177\n",
      "epoch: 169, val_loss: 0.01698611848629438\n",
      "epoch: 170, val_loss: 0.01675634258068525\n",
      "epoch: 171, val_loss: 0.016514404748494808\n",
      "epoch: 172, val_loss: 0.01628577780838196\n",
      "epoch: 173, val_loss: 0.0160582079910315\n",
      "epoch: 174, val_loss: 0.015816417164527453\n",
      "epoch: 175, val_loss: 0.015587502732299842\n",
      "epoch: 176, val_loss: 0.015342890141675105\n",
      "epoch: 177, val_loss: 0.015120669411352048\n",
      "epoch: 178, val_loss: 0.014900992481181255\n",
      "epoch: 179, val_loss: 0.014667325939696569\n",
      "epoch: 180, val_loss: 0.014434722896951895\n",
      "epoch: 181, val_loss: 0.014181354584602209\n",
      "epoch: 182, val_loss: 0.013962849043309689\n",
      "epoch: 183, val_loss: 0.013719834458942596\n",
      "epoch: 184, val_loss: 0.013483579270541668\n",
      "epoch: 185, val_loss: 0.01324877544091298\n",
      "epoch: 186, val_loss: 0.01300504280684086\n",
      "epoch: 187, val_loss: 0.012766782409296585\n",
      "epoch: 188, val_loss: 0.012547455154932462\n",
      "epoch: 189, val_loss: 0.012311166582199244\n",
      "epoch: 190, val_loss: 0.012088733510329174\n",
      "epoch: 191, val_loss: 0.011847592388781218\n",
      "epoch: 192, val_loss: 0.01161836782613626\n",
      "epoch: 193, val_loss: 0.01141076090817268\n",
      "epoch: 194, val_loss: 0.011185213780173888\n",
      "epoch: 195, val_loss: 0.010964479225759324\n",
      "epoch: 196, val_loss: 0.010750170295628218\n",
      "epoch: 197, val_loss: 0.0105294376038588\n",
      "epoch: 198, val_loss: 0.01033203647686885\n",
      "epoch: 199, val_loss: 0.010120001406623768\n",
      "epoch: 200, val_loss: 0.009913503478925962\n",
      "epoch: 201, val_loss: 0.009711156026102029\n",
      "epoch: 202, val_loss: 0.009516798031444732\n",
      "epoch: 203, val_loss: 0.009330820435514817\n",
      "epoch: 204, val_loss: 0.009139845720850505\n",
      "epoch: 205, val_loss: 0.008961919623498734\n",
      "epoch: 206, val_loss: 0.008783554013531942\n",
      "epoch: 207, val_loss: 0.00860957235384446\n",
      "epoch: 208, val_loss: 0.00844179717107461\n",
      "epoch: 209, val_loss: 0.00828085639155828\n",
      "epoch: 210, val_loss: 0.00812799920542882\n",
      "epoch: 211, val_loss: 0.007983128970059065\n",
      "epoch: 212, val_loss: 0.007833377887996344\n",
      "epoch: 213, val_loss: 0.0076880804263055325\n",
      "epoch: 214, val_loss: 0.00759605522482441\n",
      "epoch: 215, val_loss: 0.007460158640662065\n",
      "epoch: 216, val_loss: 0.00732349855108903\n",
      "epoch: 217, val_loss: 0.007194131791878205\n",
      "epoch: 218, val_loss: 0.007071476537161148\n",
      "epoch: 219, val_loss: 0.00695626727806834\n",
      "epoch: 220, val_loss: 0.006846623387760841\n",
      "epoch: 221, val_loss: 0.006740790863449757\n",
      "epoch: 222, val_loss: 0.006642978960791459\n",
      "epoch: 223, val_loss: 0.006552450430507843\n",
      "epoch: 224, val_loss: 0.006465158496911709\n",
      "epoch: 225, val_loss: 0.0063854948474237555\n",
      "epoch: 226, val_loss: 0.006307393133353729\n",
      "epoch: 227, val_loss: 0.006236207635643391\n",
      "epoch: 228, val_loss: 0.00617012417373749\n",
      "epoch: 229, val_loss: 0.00610804776302897\n",
      "epoch: 230, val_loss: 0.00605235997444162\n",
      "epoch: 231, val_loss: 0.006000243127346039\n",
      "epoch: 232, val_loss: 0.005952198452387865\n",
      "epoch: 233, val_loss: 0.005908435461326287\n",
      "epoch: 234, val_loss: 0.005868361080781772\n",
      "epoch: 235, val_loss: 0.005832461067117178\n",
      "epoch: 236, val_loss: 0.005798775845995316\n",
      "epoch: 237, val_loss: 0.005768464555820594\n",
      "epoch: 238, val_loss: 0.005741182714700699\n",
      "epoch: 239, val_loss: 0.005716251030277748\n",
      "epoch: 240, val_loss: 0.005695471325172828\n",
      "epoch: 241, val_loss: 0.005675346375657962\n",
      "epoch: 242, val_loss: 0.0056584577004496865\n",
      "epoch: 243, val_loss: 0.0056428095110907005\n",
      "epoch: 244, val_loss: 0.005628739376194202\n",
      "epoch: 245, val_loss: 0.005616925083673918\n",
      "epoch: 246, val_loss: 0.005606558747016466\n",
      "epoch: 247, val_loss: 0.005597578863111826\n",
      "epoch: 248, val_loss: 0.005589630705519364\n",
      "epoch: 249, val_loss: 0.0055825102071349435\n",
      "epoch: 250, val_loss: 0.005576508657003825\n",
      "epoch: 251, val_loss: 0.005571632001262445\n",
      "epoch: 252, val_loss: 0.005567279930871267\n",
      "epoch: 253, val_loss: 0.005563675855787901\n",
      "epoch: 254, val_loss: 0.00556064432916733\n",
      "epoch: 255, val_loss: 0.005558069329708815\n",
      "epoch: 256, val_loss: 0.005555936923393836\n",
      "epoch: 257, val_loss: 0.005554153798864438\n",
      "epoch: 258, val_loss: 0.005552676398880207\n",
      "epoch: 259, val_loss: 0.005551388451399712\n",
      "epoch: 260, val_loss: 0.005550452006550936\n",
      "epoch: 261, val_loss: 0.0055495898167674355\n",
      "epoch: 262, val_loss: 0.005548873343146765\n",
      "epoch: 263, val_loss: 0.00554844020650937\n",
      "epoch: 264, val_loss: 0.005547876075769846\n",
      "epoch: 265, val_loss: 0.005547724485110778\n",
      "epoch: 266, val_loss: 0.00554726580874278\n",
      "epoch: 267, val_loss: 0.0055470961289337045\n",
      "epoch: 268, val_loss: 0.005546971797369993\n",
      "epoch: 269, val_loss: 0.005547038852595366\n",
      "epoch: 270, val_loss: 0.005546887261936298\n",
      "epoch: 271, val_loss: 0.005546720519375343\n",
      "epoch: 272, val_loss: 0.0055464323466786975\n",
      "epoch: 273, val_loss: 0.005546447140379594\n",
      "epoch: 274, val_loss: 0.00554657276146687\n",
      "epoch: 275, val_loss: 0.0055462469776662495\n",
      "epoch: 276, val_loss: 0.005546226810950499\n",
      "epoch: 277, val_loss: 0.005547323192541416\n",
      "epoch: 278, val_loss: 0.005546180961223749\n",
      "epoch: 279, val_loss: 0.005546260195282789\n",
      "epoch: 280, val_loss: 0.005546322844635982\n",
      "epoch: 281, val_loss: 0.005546960621499098\n",
      "epoch: 282, val_loss: 0.005546188375984247\n",
      "epoch: 283, val_loss: 0.00554633355484559\n",
      "epoch: 284, val_loss: 0.005547344218939543\n",
      "epoch: 285, val_loss: 0.005546101082402926\n",
      "epoch: 286, val_loss: 0.005546268827926654\n",
      "epoch: 287, val_loss: 0.0055462273482519845\n",
      "epoch: 288, val_loss: 0.005547663304381645\n",
      "epoch: 289, val_loss: 0.005546663063936508\n",
      "epoch: 290, val_loss: 0.005546068378652518\n",
      "epoch: 291, val_loss: 0.00554655406337518\n",
      "epoch: 292, val_loss: 0.0055481038915996365\n",
      "epoch: 293, val_loss: 0.00554618386265177\n",
      "epoch: 294, val_loss: 0.006250716101091642\n",
      "epoch: 295, val_loss: 0.008106230185008965\n",
      "epoch: 296, val_loss: 0.005558449989901139\n",
      "epoch: 297, val_loss: 0.005546465659370789\n",
      "epoch: 298, val_loss: 0.0056275063767456095\n",
      "epoch: 299, val_loss: 0.009813936283955207\n",
      "epoch: 300, val_loss: 0.0055672808621938415\n",
      "epoch: 301, val_loss: 0.013074760181972614\n",
      "epoch: 302, val_loss: 0.0072093604920575255\n",
      "epoch: 303, val_loss: 0.005548828460562687\n",
      "epoch: 304, val_loss: 0.005626102013943287\n",
      "epoch: 305, val_loss: 0.010523849381850315\n",
      "epoch: 306, val_loss: 0.005564745981246233\n",
      "epoch: 307, val_loss: 0.005547329102857755\n",
      "epoch: 308, val_loss: 0.005827908117610674\n",
      "epoch: 309, val_loss: 0.0061616057243484715\n",
      "epoch: 310, val_loss: 0.00633757346524642\n",
      "epoch: 311, val_loss: 0.03943545944415606\n",
      "epoch: 312, val_loss: 0.03790965217810411\n",
      "epoch: 313, val_loss: 0.006498803312961872\n",
      "epoch: 314, val_loss: 0.00671832596596617\n",
      "epoch: 315, val_loss: 0.007626325823366642\n",
      "epoch: 316, val_loss: 0.005588051182432816\n",
      "epoch: 317, val_loss: 0.005551215010480239\n",
      "epoch: 318, val_loss: 0.018421782180666924\n",
      "epoch: 319, val_loss: 0.01765626697586133\n",
      "epoch: 320, val_loss: 0.005828735669358418\n",
      "epoch: 321, val_loss: 0.007884912622662691\n",
      "epoch: 322, val_loss: 0.005565257277339697\n",
      "epoch: 323, val_loss: 0.01272489596158266\n",
      "epoch: 324, val_loss: 0.008519699797034264\n",
      "epoch: 325, val_loss: 0.01572708090623984\n",
      "epoch: 326, val_loss: 0.019679230279647388\n",
      "epoch: 327, val_loss: 0.039523681482443444\n",
      "epoch: 328, val_loss: 0.016363719048408363\n",
      "epoch: 329, val_loss: 0.04296012939168857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:130] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 22\u001b[0m\n\u001b[1;32m     12\u001b[0m input_node_features, targets \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnormalized_x\u001b[39m.\u001b[39mto(device), data\u001b[39m.\u001b[39mnormalized_y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[39m# y_values_normalized = np.concatenate([data.normalized_y])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# y_mean_per_batch = np.mean(y_values_normalized)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# n = len(data.normalized_y)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# counter += 1\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# y_mean_per_batch_tensor = torch.tensor(y_mean_per_batch)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m predicted \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     23\u001b[0m train_loss \u001b[39m=\u001b[39m loss_fct(predicted, targets)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m, in \u001b[0;36mGnnModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     15\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> 16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[1;32m     17\u001b[0m     \u001b[39m# x = F.relu(x)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m# x = F.dropout(x, training=self.training)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# x = self.conv2(x, edge_index)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py:255\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    252\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_updater(edge_index, alpha\u001b[39m=\u001b[39malpha, edge_attr\u001b[39m=\u001b[39medge_attr)\n\u001b[1;32m    254\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, alpha\u001b[39m=\u001b[39;49malpha, size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcat:\n\u001b[1;32m    258\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_channels)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:480\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    483\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:604\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    592\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    593\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    594\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[39m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    605\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/experimental.py:115\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[39m'\u001b[39m\u001b[39mdisable_dynamic_shapes\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m     \u001b[39mfor\u001b[39;00m required_arg \u001b[39min\u001b[39;00m required_args:\n\u001b[1;32m    118\u001b[0m         index \u001b[39m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:125\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, index\u001b[39m=\u001b[39;49mindex, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    126\u001b[0m                             dim\u001b[39m=\u001b[39;49mdim, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce(x, index, ptr, dim_size, dim, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:176\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m segment(x, ptr, reduce\u001b[39m=\u001b[39mreduce)\n\u001b[1;32m    175\u001b[0m \u001b[39massert\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/utils/scatter.py:70\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     69\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39;49mscatter_add_(dim, index, src)\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# find the average per batch\n",
    "\n",
    "# Train the model\n",
    "# mse_loss = 0\n",
    "# counter = 0\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    data = next(iter(train_dl))\n",
    "    for idx in range(len(train_dl)):\n",
    "        \n",
    "    # for idx, data in enumerate(train_dl):\n",
    "        input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "        # y_values_normalized = np.concatenate([data.normalized_y])\n",
    "        # y_mean_per_batch = np.mean(y_values_normalized)\n",
    "        # n = len(data.normalized_y)\n",
    "        # y_mean_per_batch = torch.tensor(y_mean_per_batch * np.ones((n, 1)))\n",
    "        # error_per_batch = torch.mean((data.normalized_y - y_mean_per_batch)**2)\n",
    "        # mse_loss += error_per_batch.item()\n",
    "        # counter += 1\n",
    "        # y_mean_per_batch_tensor = torch.tensor(y_mean_per_batch)\n",
    "\n",
    "        predicted = model(data)\n",
    "        train_loss = loss_fct(predicted, targets)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({\"train_loss\": train_loss.item(), \"epoch\": epoch, \"step\": idx})\n",
    "        # print(f\"epoch: {epoch}, step: {idx}, loss: {train_loss.item()}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    val_loss = validate_model(model, valid_dl, loss_fct, device)\n",
    "    \n",
    "    # early stopping\n",
    "    # early_stopping(train_loss, val_loss)\n",
    "    # if early_stopping.early_stop:\n",
    "    #   print(\"We are at epoch:\", i)\n",
    "    #   break\n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "    print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "        \n",
    "wandb.summary[\"val_loss\"] = val_loss\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
